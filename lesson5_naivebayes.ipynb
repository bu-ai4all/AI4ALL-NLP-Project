{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run this every time you open the spreadsheet\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from collections import Counter\n",
    "import lib\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and inspect the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the data.\n",
    "# This function returns tweets and test_tweets, both lists of tweets\n",
    "tweets, test_tweets = lib.read_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Learn a Naive Bayes classifier\n",
    "\n",
    "To construct our Naive Bayes classifier, we first need to calculate two things:\n",
    "\n",
    "### Prior probabilities of categories\n",
    "We need to calculate $P(C_i)$ for each category $C_i \\in \\{\\text{Energy}, \\text{Food}, \\text{Medical}, \\text{Water}, \\text{None}\\}$. \n",
    "\n",
    "We estimate $P(C_i)$ by $\\frac{\\text{# tweets about }C_i}{\\text{# tweets}}$\n",
    "\n",
    "### Conditional probabilities of tokens\n",
    "For each token (i.e. word) $x_j$ and each category $C_i$, we need to calculate $P(x_j|C_i)$.\n",
    "\n",
    "We estimate $P(x_j|C_i) = \\frac{P(x_j \\text{ and } C_i)}{P(C_i)}$ by $\\frac{\\text{# tweets about }C_i \\text{ containing }x_j}{\\text{# tweets about }C_i}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exercise 1, step-by-step version\n",
    "\n",
    "# The function below has two arguments: a list of tweets, and a category c\n",
    "# which is a string equal to one of \"Energy\", \"Food\", \"Medical\", \"Water\", \"None\".\n",
    "# The function should calculate the two things described above.\n",
    "# Fill in the blanks.\n",
    "\n",
    "\n",
    "def calc_probs(tweets, c):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        tweets: a list of tweets\n",
    "        c: a string representing a category; one of \"Energy\", \"Food\", \"Medical\", \"Water\", \"None\". \n",
    "    Returns:\n",
    "        prob_c: the prior probability of category c\n",
    "        token_probs: a Counter mapping each token to P(token|category c)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Calculate the total number of tweets\n",
    "    num_tweets = __________\n",
    "\n",
    "    \n",
    "    # Step 2: Calculate the number of tweets that are about category c.\n",
    "    # Save the answer to a variable called num_tweets_about_c.\n",
    "    # Remember c is a string, and you can get the category of a tweet via tweet.category\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "\n",
    "    \n",
    "    \n",
    "    # Step 3: Calculate the probability of category c using the answers from Steps 1 and 2.\n",
    "    # Hint: be careful when you divide two integers!\n",
    "    prob_c = __________\n",
    "    \n",
    "    \n",
    "    # Step 4: Create an empty Counter called token_counts.\n",
    "    # (We will use it to map each token to the number of category-c tweets containing that token.)\n",
    "    token_counts = __________\n",
    "    \n",
    "    \n",
    "    # Step 5 (tricky): Use a for-loop to iterate over the list of tweets.\n",
    "    # Use an if-statement to check whether the tweet is in category c.\n",
    "    # If it is, iterate over the tokens of the tweet (which you can access via tweet.tokenSet) using a for-loop.\n",
    "    # For each token, increment its count in token_counts.\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Step 6: Create an empty Counter called token_probs.\n",
    "    # (We will use it to map each token to P(token | category c), \n",
    "    # i.e. the fraction of all category-c tweets that contain the token)\n",
    "    token_probs = __________\n",
    "    \n",
    "    \n",
    "    # Step 7: Now fill token_probs.\n",
    "    # For each token->count in token_counts, you want to add token->fraction to token_probs.\n",
    "    # Use a for-loop over token_counts. \n",
    "    # Remember that when you iterate over a dictionary/Counter, you access the keys.\n",
    "    # You'll need to use the variable num_tweets_about_c.\n",
    "    # Be careful when you divide integers!\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "\n",
    "    \n",
    "    \n",
    "    print(\"Class %s has prior probability %.2f\" % (c, prob_c))    \n",
    "    return prob_c, token_probs\n",
    "\n",
    "\n",
    "prob_food, token_probs_food = calc_probs(tweets, \"Food\")\n",
    "prob_water, token_probs_water = calc_probs(tweets, \"Water\")\n",
    "prob_energy, token_probs_energy = calc_probs(tweets, \"Energy\")\n",
    "prob_medical, token_probs_medical = calc_probs(tweets, \"Medical\")\n",
    "prob_none, token_probs_none = calc_probs(tweets, \"None\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### See what your model has learnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For each category c, print out the tokens that maximize P(c|token)\n",
    "\n",
    "token_probs = {'Food': token_probs_food, 'Water': token_probs_water, 'Energy': token_probs_energy, 'Medical': token_probs_medical,'None': token_probs_none}\n",
    "prior_probs = {'Food': prob_food, 'Water': prob_water, 'Energy': prob_energy, 'Medical': prob_medical, 'None': prob_none}\n",
    "lib.most_discriminative(tweets, token_probs, prior_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Naive Bayes classifier\n",
    "\n",
    "Now we've calculated $P(C_i)$ and $P(x_j|C_i)$, we can classify any tweet!\n",
    "\n",
    "Given a tweet which is a set of tokens $\\{x_1,...,x_n\\}$, the posterior probability of each category $C_i$ is\n",
    "\n",
    "$P(C_i | x_1,...,x_n) \\propto P(C_i) \\times P(x_1|C_i) \\times P(x_2|C_i) ... \\times P(x_n|C_i)$\n",
    "\n",
    "We just need to calculate this for each category then determine which is largest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exercise 2. \n",
    "\n",
    "# Complete this function that calculates the posterior probability of P(c|tweet).\n",
    "\n",
    "def get_posterior_prob(tweet, prob_c, token_probs):\n",
    "    \"\"\"Calculate the posterior P(c|tweet). \n",
    "    (Actually, calculate something proportional to it).\n",
    "    \n",
    "    Inputs:\n",
    "        tweet: a tweet\n",
    "        prob_c: the prior probability of category c\n",
    "        token_probs: a Counter mapping each token P(token|c)\n",
    "    Return:\n",
    "        The posterior P(c|tweet).\n",
    "    \"\"\"\n",
    "\n",
    "    ##### YOUR CODE STARTS HERE #####\n",
    "    \n",
    "    # Hint: first set posterior to prob_c, then use a for-loop over tweet.tokenSet\n",
    "    # to repeatedly multiply posterior by P(token|c)\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    ##### YOUR CODE ENDS HERE #####\n",
    "    \n",
    "    return posterior\n",
    "\n",
    "\n",
    "\n",
    "# Now you've written the function, look at the output for P(Energy|\"No power in Riverdale\").\n",
    "# What's gone wrong? \n",
    "# Try editing your function above to print out each token and token_probs[token].\n",
    "# Can you see what went wrong? How might you fix it?\n",
    "\n",
    "riverdale_tweet = lib.Tweet(\"No power in Riverdale\", \"Energy\", \"need\")\n",
    "print(\"P(Energy|'No power in Riverdale') = \", get_posterior_prob(riverdale_tweet, prob_energy, token_probs_energy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This cell defines the classification function, that takes a tweet \n",
    "# and decides which category is most likely using the posteriors you just calculated.\n",
    "\n",
    "\n",
    "# OPTIONAL EXERCISE (come back to it once you've reached the end of the notebook).\n",
    "# Rewrite this function to be less repetitive i.e. don't repeat things 5 times.\n",
    "# There are several possible solutions; you might want to use lists or dictionaries.\n",
    "# You might also want to rewrite the earlier code that computed prob_food, token_probs_food etc.\n",
    "\n",
    "\n",
    "def classify_nb(tweet):\n",
    "    \"\"\"Classifies a tweet. Calculates the posterior P(c|tweet) for each category c, \n",
    "    and returns the category with largest posterior.\n",
    "    Input:\n",
    "        tweet\n",
    "    Output:\n",
    "        string equal to most-likely category for this tweet\n",
    "    \"\"\"\n",
    "    posterior_food_prob = get_posterior_prob(tweet, prob_food, token_probs_food)\n",
    "    posterior_water_prob = get_posterior_prob(tweet, prob_water, token_probs_water)\n",
    "    posterior_energy_prob = get_posterior_prob(tweet, prob_energy, token_probs_energy)\n",
    "    posterior_medical_prob = get_posterior_prob(tweet, prob_medical, token_probs_medical)\n",
    "    posterior_none_prob = get_posterior_prob(tweet, prob_none, token_probs_none)\n",
    "    \n",
    "    max_posterior = max([posterior_food_prob, posterior_water_prob, posterior_energy_prob, posterior_medical_prob, posterior_none_prob])\n",
    "    if posterior_food_prob == max_posterior:\n",
    "        return 'Food'\n",
    "    elif posterior_water_prob == max_posterior:\n",
    "        return 'Water'\n",
    "    elif posterior_energy_prob == max_posterior:\n",
    "        return 'Energy'\n",
    "    elif posterior_medical_prob == max_posterior:\n",
    "        return 'Medical'\n",
    "    else:\n",
    "        return 'None'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compare true labels and predicted labels in a table\n",
    "\n",
    "predictions = [(tweet, classify_nb(tweet)) for tweet in test_tweets] # a list of (tweet, prediction) pairs\n",
    "lib.show_predictions(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get average F1 score for the test set\n",
    "\n",
    "predictions = [(tweet, classify_nb(tweet)) for tweet in test_tweets] # maps each test tweet to its predicted label\n",
    "lib.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get average F1 score for the TRAINING set.\n",
    "# Compare with average F1 for test set above. What's the reason for the difference?\n",
    "\n",
    "trainset_predictions = [(tweet, classify_nb(tweet)) for tweet in tweets] # maps each training tweet to its predicted label\n",
    "lib.evaluate(trainset_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lib.show_confusion_matrix(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
